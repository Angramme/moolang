use std::{iter::Peekable, ops::{Deref, DerefMut}};

use crate::{tokenizer::Token, tokenizer::Type as TokenType, tokenizer::{Tokenizer, Location}};


pub enum AST
{
    Literal(String),
    Lambda(AST, AST),
    Nop,
}

pub enum Type {
    Literal, Lambda, SkipToken(TokenType)
}

struct ParseError (String);


pub trait Parseable<I: Iterator<Item = Token>> {
    fn next(&self, s: I) -> Option<Result<(Lazy<I>, Box<dyn Parseable<I>>), ParseError>>;
}

impl<I: Iterator<Item = Token>> From<Type> for dyn Parseable<I> {
    fn from(type_: Type) -> Self {
        match type_ {
            Type::Literal => todo!(),
            Type::Lambda => todo!(),
            Type::SkipToken(token) => todo!(),
        }
    }
}


impl Type {
    pub fn deep_parse<I: Iterator<Item = Token>>(&self, stream: &mut I) -> Result<AST, ParseError> {
        let current = self._parseable()?;
        while let Some(next) = current.next(stream) {
            let (ast, next) = next?;
            
        }
        todo!()
    }
}


pub struct Lazy<I: Iterator<Item = Token>> {
    type_: Type,
    stream: I,
}


impl<I: Iterator<Item = Token>> Lazy<I> {
    pub fn deep_parse(&mut self) -> Result<AST, ParseError> { 
        self.type_.deep_parse(&mut self.stream)
    }
    pub fn next(&mut self) -> Option<Result<(Lazy<I>, Box<dyn Parseable<I>>), ParseError>> {
        self.type_.parseable(&mut self.stream)
            .map(|parseable| Ok((self.clone(), parseable)))
    }
    pub fn type_(&self) -> Type {
        self.type_
    }
}

impl<I: Iterator<Item = Token>> From<I> for Lazy<I> {
    fn from(stream: I) -> Self {
        Self {
            type_: Type::Literal,
            stream
        }
    }
}




fn parse_literal<I: Iterator<Item = Token>>(s: &mut I) -> Result<AST<I>, ParseError> {
    let tok = s.next().unwrap();
    match tok.type_ {
        TokenType::Literal(s) => Ok(AST::Literal(s)),
        _ => Err(ParseError (format!("Expected literal, got {:?}", tok.type_)))
    }
}

fn parse_token<I: Iterator<Item = Token>>(token: TokenType, s: &mut I) -> Result<AST<I>, ParseError> {
    let tok = s.next().unwrap();
    if tok.type_ == token {
        Ok(AST::Nop)
    } else {
        Err(ParseError (format!("Expected token {:?}, got {:?}", token, tok.type_)))
    }
}

fn parse_module<I: Iterator<Item = Token>>(tokens: &mut I) -> Result<AST<I>, ParseError> {
    todo!();
    // let mut asts = Vec::new();
    // while let Some(token) = tokens.peek() {
    //     match token.type_ {
    //         _ => asts.push(parse_statement(tokens)?),
    //     }
    // }
    // Ok(Type::Module(asts))
}

fn parse_lambda<I: Iterator<Item = Token>>(tokens: &mut I) -> Result<AST<I>, ParseError> {
    todo!();
    // let mut asts = Vec::new();
    // while let Some(token) = tokens.peek() {
    //     match token.type_ {
    //         _ => asts.push(parse_statement(tokens)?),
    //     }
    // }
    // Ok(Type::Module(asts))
}

// pub trait Parseable<'a, I>: Sized + From<&'a mut Peekable<I>> + Into<&'a mut Peekable<I>> + Iterator<Item = Result<T, LocalizedError>>
// where I: Iterator<Item = Token> + 'a
// {}


// fn assemble<'a, T, I, P>(tokens: &'a mut Peekable<I>) -> &'a mut Peekable<I>
// where I: Iterator<Item = Token>, P: Parseable<'a, T, I>
// {
//     let mut pars: P = tokens.into();
    
//     pars.into()
// }